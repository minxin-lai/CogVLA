# CogVLA Vision Backbone å®Œæ•´è§£æ

> ä»è¾“å…¥åˆ°è¾“å‡ºçš„å®Œæ•´æ•°æ®æµä¸äº¤äº’æœºåˆ¶

---

## ğŸ¯ æ ¸å¿ƒæ¦‚è§ˆ

**ä¸€å¥è¯æ€»ç»“**: å›¾åƒ(18é€šé“) + æ–‡æœ¬æŒ‡ä»¤ â†’ é€šè¿‡åŒç¼–ç å™¨+ä¸‰æ¬¡äº¤äº’ â†’ è¾“å‡º192ä¸ªèåˆçš„è§†è§‰tokens

**ä¸‰æ¬¡å…³é”®äº¤äº’**:
1. **FiLMè°ƒåˆ¶** (æ·±åº¦äº¤äº’): æ–‡æœ¬é€ç»´åº¦è°ƒåˆ¶è§†è§‰ç‰¹å¾
2. **Aggregation Tokens** (å‹ç¼©äº¤äº’): 256 patches â†’ 64 tokens
3. **MoE Router** (æ¡ä»¶åŒ–äº¤äº’): æ–‡æœ¬å†³å®šä¸“å®¶èåˆæƒé‡

---

## ğŸ“¥ è¾“å…¥å‡†å¤‡

```python
# è¾“å…¥æ•°æ®
pixel_values:        [B, 18, 224, 224]  # 3å¼ å›¾ Ã— 6é€šé“
language_embeddings: [B, 20, 4096]       # æ–‡æœ¬æŒ‡ä»¤ï¼Œ20ä¸ªtoken

# 18é€šé“ = 3å¼ å›¾ Ã— (SigLIP 3é€šé“ + DINOv2 3é€šé“)
# 3å¼ å›¾é€šå¸¸æ˜¯: Primary camera + Wrist camera 1 + Wrist camera 2
```

---

## ğŸ”„ å®Œæ•´æ‰§è¡Œæµç¨‹

### Step 1: æ–‡æœ¬é¢„å¤„ç†

```python
avg_lang = language_embeddings.mean(dim=1)  # [B, 20, 4096] â†’ [B, 4096]
```

**ä½œç”¨**: å°†å˜é•¿æŒ‡ä»¤å‹ç¼©æˆå›ºå®šé•¿åº¦çš„å…¨å±€è¯­ä¹‰å‘é‡ï¼Œç”¨äºåç»­æ‰€æœ‰äº¤äº’

---

### Step 2: å›¾åƒåˆ†ç¦»

```python
images = torch.split(pixel_values, [6, 6, 6], dim=1)
# â†’ img1[B,6,224,224], img2[B,6,224,224], img3[B,6,224,224]

# æ¯å¼ å›¾å†åˆ†ç¦»åŒç¼–ç å™¨è¾“å…¥
img_regular, img_fused = torch.split(img, [3, 3], dim=1)
# img_regular: [B, 3, 224, 224] â†’ SigLIP
# img_fused:   [B, 3, 224, 224] â†’ DINOv2
# æ³¨æ„: åŒä¸€å¼ RGBå›¾ï¼Œå¤åˆ¶äº†ä¸¤ä»½ï¼
```

**è®¾è®¡ç†ç”±**:
- **SigLIP**: æ“…é•¿è¯­ä¹‰è¯†åˆ« ("è¿™æ˜¯è‹¹æœ")
- **DINOv2**: æ“…é•¿å‡ ä½•å®šä½ ("åœ¨å·¦è¾¹")

---

### Step 3: åŒç¼–ç å™¨å¤„ç†ï¼ˆå«äº¤äº’1å’Œ2ï¼‰

å¯¹æ¯å¼ å›¾æ‰§è¡Œï¼ˆå¾ªç¯3æ¬¡ï¼‰ï¼š

#### 3.1 äº¤äº’1: FiLMè°ƒåˆ¶ ğŸ”¥

**å‘ç”Ÿä½ç½®**: ViTçš„æ¯ä¸€å±‚ï¼ˆ27å±‚ï¼‰

**æœºåˆ¶**:
```python
# åœ¨æ¯ä¸ª Transformer block ä¸­
def forward(self, x, avg_lang):
    # æ–‡æœ¬ â†’ è°ƒåˆ¶å‚æ•°
    gamma = MLP_scale(avg_lang)  # [B, 4096] â†’ [B, 1024]
    beta = MLP_shift(avg_lang)   # [B, 4096] â†’ [B, 1024]
    
    # æ ‡å‡†Attention
    x = x + self.attn(self.norm1(x))
    
    # FiLMè°ƒåˆ¶ï¼ˆå…³é”®ï¼ï¼‰
    x = x * (1 + gamma.unsqueeze(1)) + beta.unsqueeze(1)
    
    # MLP
    x = x + self.mlp(self.norm2(x))
    return x
```

**ä½œç”¨ç¤ºä¾‹**:
```python
# æŒ‡ä»¤: "pick up the red apple"
# gammaä¼šå¼ºåŒ–çº¢è‰²ç›¸å…³ç»´åº¦çš„æƒé‡
x_new[red_dim] = x_old[red_dim] * (1 + 0.5) + 0.1  # æ”¾å¤§
x_new[noise_dim] = x_old[noise_dim] * (1 - 0.2) + 0.0  # æŠ‘åˆ¶
```

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| äº¤äº’æ·±åº¦ | æ·±åº¦ï¼ˆ27å±‚ï¼Œé€ç»´åº¦è°ƒåˆ¶ï¼‰ |
| ç²’åº¦ | Per-dimension (1024ç»´) |
| ä¿¡æ¯æµ | å•å‘: æ–‡æœ¬ â†’ è§†è§‰ |
| è®¾è®¡å“²å­¦ | æ–‡æœ¬å‘Šè¯‰è§†è§‰"å…³æ³¨ä»€ä¹ˆç‰¹å¾" (What) |

---

#### 3.2 äº¤äº’2: Aggregation Tokens ğŸ¯

**æœºåˆ¶**:
```python
# ViTå†…éƒ¨å¤„ç†
x = patch_embed(img_regular)              # [B, 256, 1024] - å›¾åƒåˆ†patch
vision_aggr_batch = vision_aggr.expand(B, -1, -1)  # [B, 64, 1024] - å¯å­¦ä¹ token
x = torch.cat([x, vision_aggr_batch], dim=1)  # [B, 320, 1024]

# é€šè¿‡27å±‚Transformerï¼ˆæ¯å±‚éƒ½è¢«FiLMè°ƒåˆ¶ï¼‰
for blk in blocks:
    x = blk(x, avg_lang)  # 320ä¸ªtokenäº’ç›¸çœ‹
    # 64ä¸ªaggregation tokensé€šè¿‡attention "å¸æ”¶" 256ä¸ªpatchä¿¡æ¯

# åªä¿ç•™aggregation tokens
output = x[:, 256:]  # [B, 320, 1024] â†’ [B, 64, 1024]
```

**å·¥ä½œåŸç†**:
```
åˆå§‹: [256 patches] + [64 aggr tokens (éšæœºåˆå§‹åŒ–)]
       â†“ 27å±‚ Self-Attention (åœ¨FiLMè°ƒåˆ¶ä¸‹)
æœ€ç»ˆ: [64 aggr tokens (åŒ…å«256 patchesçš„å‹ç¼©ä¿¡æ¯)]
```

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| å‹ç¼©æ¯” | 75% (256 â†’ 64 tokens) |
| æ–‡æœ¬å½±å“ | é—´æ¥é€šè¿‡FiLMï¼ˆä¸ç›´æ¥å‚ä¸attentionï¼‰ |
| ä¿¡æ¯æµ | Patches â†’ Aggregation tokens |
| è®¾è®¡å“²å­¦ | é«˜æ•ˆå‹ç¼©è§†è§‰ä¿¡æ¯ (Compress) |

**åŒç¼–ç å™¨è¾“å‡º**:
```python
patches_siglip = featurizer(img_regular, avg_lang)       # [B, 64, 1024]
patches_dino = fused_featurizer(img_fused, avg_lang)     # [B, 64, 1152]
```

---

### Step 4: æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦

```python
proj_siglip = self.featurizer_proj(patches_siglip)      # [B, 64, 4096]
proj_dino = self.fused_featurizer_proj(patches_dino)    # [B, 64, 4096]
```

**ä½œç”¨**: å°†ä¸åŒç»´åº¦çš„ç‰¹å¾ç»Ÿä¸€åˆ°LLMç©ºé—´ï¼ˆ4096ç»´ï¼‰

---

### Step 5: äº¤äº’3: MoE Router ğŸšï¸

**æœºåˆ¶**:
```python
def forward(self, inputs_embeds, seq_embeds):
    # inputs_embeds = [proj_siglip, proj_dino]
    # seq_embeds = avg_lang
    
    # æ–‡æœ¬ â†’ ä¸“å®¶æƒé‡
    logits = self.router(seq_embeds)  # [B, 4096] â†’ [B, 2]
    # router = MLP: Linear(4096â†’4096) â†’ GELU â†’ Linear(4096â†’2)
    
    ratios = torch.softmax(logits, dim=-1)  # [B, 2]
    # ä¾‹å¦‚: [0.7, 0.3]
    
    # åŠ æƒèåˆ
    output = ratios[:, 0].view(-1,1,1) * proj_siglip + \
             ratios[:, 1].view(-1,1,1) * proj_dino
    return output  # [B, 64, 4096]
```

**ä»»åŠ¡è‡ªé€‚åº”ç¤ºä¾‹**:
```python
# åœºæ™¯1: "pick up the red cube" (éœ€è¦é¢œè‰²è¯­ä¹‰)
avg_lang_1 â†’ MLP â†’ [0.92, 0.08]  # ä¸»è¦ç”¨SigLIP

# åœºæ™¯2: "move 5cm to the left" (éœ€è¦ç©ºé—´å®šä½)
avg_lang_2 â†’ MLP â†’ [0.25, 0.75]  # ä¸»è¦ç”¨DINOv2
```

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| äº¤äº’æ·±åº¦ | æµ…å±‚ï¼ˆåŠ æƒå¹³å‡ï¼‰ |
| ç²’åº¦ | Per-sample (2ä¸ªæ ‡é‡) |
| ä¿¡æ¯æµ | æ–‡æœ¬ â†’ æƒé‡ â†’ è§†è§‰ |
| è®¾è®¡å“²å­¦ | æ–‡æœ¬å†³å®š"ç”¨å“ªä¸ªä¸“å®¶" (Which) |

âš ï¸ **é‡è¦**: MoE Routeræ˜¯**ç®€å•çš„åŠ æƒå¹³å‡**ï¼Œä¸æ˜¯Cross-Attentionï¼

---

### Step 6: æ‹¼æ¥å¤šå›¾è¾“å‡º

```python
# å¯¹3å¼ å›¾é‡å¤Step 3-5
all_image_embeds = []
for img in images:  # 3æ¬¡
    fused = process_one_image(img, avg_lang)  # [B, 64, 4096]
    all_image_embeds.append(fused)

# æ‹¼æ¥æ‰€æœ‰å›¾åƒ
image_embeds = torch.cat(all_image_embeds, dim=1)  # [B, 192, 4096]
```

**æœ€ç»ˆè¾“å‡º**: 6ç»„ç‰¹å¾ (3å¼ å›¾ Ã— 2ç¼–ç å™¨) â†’ èåˆä¸º192ä¸ªè§†è§‰tokens

---

## ğŸ“Š å®Œæ•´æ•°æ®æµå›¾

```
pixel_values [B,18,224,224] + language_embeddings [B,20,4096]
        â†“
    avg_lang = mean()  [B,4096]
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“           â†“           â†“
  img1        img2        img3
[B,6,224]   [B,6,224]   [B,6,224]
    â†“           â†“           â†“
â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
â”‚ğŸ”¥ FiLMè°ƒåˆ¶ (27å±‚, æ·±åº¦äº¤äº’)      â”‚
â”‚ğŸ¯ Aggregation (Self-Attentionå‹ç¼©)â”‚
â”œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¤
SigLIP DINOv2 SigLIP DINOv2 SigLIP DINOv2
[64]  [64]   [64]  [64]   [64]  [64]
  â†“     â†“      â†“     â†“      â†“     â†“
  æŠ•å½±åˆ°4096ç»´
  â†“     â†“      â†“     â†“      â†“     â†“
â”‚ğŸšï¸ MoE Router (æ¡ä»¶åŒ–åŠ æƒ)        â”‚
  â†“           â†“           â†“
[B,64,4096] [B,64,4096] [B,64,4096]
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
      concatenate
              â†“
      [B, 192, 4096]
```

---

## ğŸ¯ ä¸‰æ¬¡äº¤äº’çš„è®¾è®¡å“²å­¦

### å¯¹æ¯”çŸ©é˜µ

| äº¤äº’ | ä½ç½® | æœºåˆ¶ | ä½œç”¨å¯¹è±¡ | ä¿¡æ¯æµ | å¤æ‚åº¦ | å¯è§£é‡Šæ€§ | è®¾è®¡ç›®æ ‡ |
|------|------|------|----------|--------|--------|----------|----------|
| **FiLM** | ViTå†…éƒ¨ | ç‰¹å¾è°ƒåˆ¶ | æ¯ä¸ªç»´åº¦ | æ–‡æœ¬â†’è§†è§‰ | O(D) | ä½ | What: å…³æ³¨ä»€ä¹ˆç‰¹å¾ |
| **Aggregation** | ViTå†…éƒ¨ | Self-Attention | Tokené—´ | Patchâ†’Aggr | O(NÂ²) | ä¸­ | Compress: é«˜æ•ˆå‹ç¼© |
| **MoE** | æŠ•å½±å | åŠ æƒå¹³å‡ | ä¸“å®¶é€‰æ‹© | æ–‡æœ¬â†’æƒé‡ | O(1) | é«˜ | Which: ç”¨å“ªä¸ªä¸“å®¶ |

### äº’è¡¥æ€§

è¿™ä¸‰ç§äº¤äº’æ˜¯**æ¸è¿›å¼ã€å¤šå±‚æ¬¡**çš„è®¾è®¡ï¼š
1. **FiLM** (ç»†ç²’åº¦): æ·±åº¦è°ƒåˆ¶ï¼Œè®©è§†è§‰ç‰¹å¾é€‚åº”ä»»åŠ¡
2. **Aggregation** (æ•ˆç‡): ä¿¡æ¯å‹ç¼©ï¼Œå‡å°‘åç»­LLMè®¡ç®—é‡
3. **MoE** (å…¨å±€): ä¸“å®¶èåˆï¼Œä»»åŠ¡è‡ªé€‚åº”é€‰æ‹©

---

## ğŸ’¡ å…³é”®è¦ç‚¹

### âœ… æ ¸å¿ƒæœºåˆ¶

1. **åŒç¼–ç å™¨æ¶æ„**: åŒä¸€å¼ å›¾é€å…¥ä¸¤ä¸ªç¼–ç å™¨ï¼Œè·å¾—äº’è¡¥ç‰¹å¾
2. **Aggregation Tokens**: 75%å‹ç¼©æ¯”ï¼Œæ˜¾è‘—å‡å°‘LLMè¾“å…¥é•¿åº¦
3. **FiLMè°ƒåˆ¶**: æ–‡æœ¬åŠ¨æ€å½±å“è§†è§‰ç¼–ç ï¼Œå…¬å¼: `x_new = x * (1 + Î³(text)) + Î²(text)`
4. **MoE Router**: ä»»åŠ¡è‡ªé€‚åº”èåˆï¼Œä¸åŒæŒ‡ä»¤â†’ä¸åŒä¸“å®¶æƒé‡

### âš ï¸ å¸¸è§è¯¯è§£

| è¯¯è§£ | äº‹å® |
|------|------|
| 6é€šé“æ˜¯3å¼ ä¸åŒå›¾ | âŒ åŒä¸€å¼ RGBå›¾å¤åˆ¶ä¸¤ä»½ï¼Œåˆ†åˆ«ç»™ä¸¤ä¸ªç¼–ç å™¨ |
| MoE Routeræœ‰Cross-Attention | âŒ åªæ˜¯ç®€å•åŠ æƒå¹³å‡ |
| æ–‡æœ¬å’Œå›¾åƒåŒå‘äº¤äº’ | âŒ å•å‘ï¼šæ–‡æœ¬â†’è§†è§‰ |
| Aggregation tokensæ‰‹å·¥è®¾è®¡ | âŒ å¯å­¦ä¹ å‚æ•°ï¼Œé€šè¿‡è®­ç»ƒä¼˜åŒ– |

### ğŸ” å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆéœ€è¦aggregation tokensï¼Ÿ**  
A: Vision Backboneè¾“å‡º256ä¸ªpatchesï¼Œç›´æ¥é€å…¥LLMä¼šå¯¼è‡´åºåˆ—è¿‡é•¿ï¼ˆ3å¼ å›¾å°±æ˜¯768 tokensï¼‰ã€‚Aggregation tokenså°†å…¶å‹ç¼©åˆ°64ä¸ªï¼Œ3å¼ å›¾åªéœ€192 tokensï¼Œå¤§å¹…å‡å°‘è®¡ç®—é‡ã€‚

**Q: FiLMåœ¨å“ªé‡Œä½œç”¨ï¼Ÿ**  
A: åœ¨ViTçš„æ¯ä¸€å±‚ï¼Œattentionä¹‹åã€MLPä¹‹å‰ã€‚27å±‚éƒ½ä¼šç”¨`avg_lang`ç”Ÿæˆgammaå’Œbetaæ¥è°ƒåˆ¶è§†è§‰ç‰¹å¾ã€‚

**Q: MoE Routerçš„æƒé‡æ˜¯å›ºå®šçš„å—ï¼Ÿ**  
A: ä¸æ˜¯ã€‚æƒé‡æ˜¯åŠ¨æ€çš„ï¼Œç”±æ–‡æœ¬é€šè¿‡MLPç”Ÿæˆã€‚ä¸åŒä»»åŠ¡ä¼šå¾—åˆ°ä¸åŒçš„ä¸“å®¶æƒé‡ã€‚

**Q: ä¸ºä»€ä¹ˆmean(dim=1)ï¼Ÿ**  
A: å°†å˜é•¿æŒ‡ä»¤(20ä¸ªtoken)å‹ç¼©æˆå›ºå®šé•¿åº¦(1ä¸ªå‘é‡)ï¼Œä¾¿äºFiLMå’ŒMoEä½¿ç”¨ã€‚æ¯ä¸ªæ ·æœ¬æœ‰è‡ªå·±çš„å…¨å±€è¯­ä¹‰å‘é‡ã€‚

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [LFP_mechanism.md](./LFP_mechanism.md) - LFPå‰ªææœºåˆ¶å®Œæ•´è¯¦è§£
- [CogVLA_TRAINING_FLOW.md](./CogVLA_TRAINING_FLOW.md) - å®Œæ•´è®­ç»ƒæµç¨‹
- [CogVLA_INTEGRATION.md](./CogVLA_INTEGRATION.md) - æ¨¡å—å®ç°ç»†èŠ‚å’Œé›†æˆæŒ‡å—

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2025-01-05  
**ä»£ç å‚è€ƒ**: `prismatic/models/vit_wrapper_reg.py`, `prismatic/models/router.py`
