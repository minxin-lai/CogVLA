# Vision Backbone æ‰§è¡Œæµç¨‹å®Œæ•´æ¢³ç†

> ä»è¾“å…¥åˆ°è¾“å‡ºçš„å®Œæ•´æ•°æ®æµè¿½è¸ª

---

## ğŸ¯ ä¸€å¥è¯æ€»ç»“

**è¾“å…¥**: å›¾åƒ(18é€šé“) + æ–‡æœ¬æŒ‡ä»¤ â†’ **è¾“å‡º**: 3å¼ å›¾ Ã— 2ä¸ªç¼–ç å™¨ = 6ç»„å‹ç¼©ç‰¹å¾

---

## ğŸ“¥ è¾“å…¥å‡†å¤‡

```python
# è¾“å…¥æ•°æ®
pixel_values:        [B, 18, 224, 224]  # 3å¼ å›¾ Ã— 6é€šé“
language_embeddings: [B, 20, 4096]       # æ–‡æœ¬æŒ‡ä»¤ï¼Œ20ä¸ªtoken

# B = batch size (ä¾‹å¦‚8)
# 18é€šé“ = 3å¼ å›¾ Ã— (SigLIP 3é€šé“ + DINOv2 3é€šé“)
```

---

## ğŸ”„ æ‰§è¡Œæµç¨‹ï¼ˆ5ä¸ªæ­¥éª¤ï¼‰

### **æ­¥éª¤1: æ–‡æœ¬å‹ç¼©**

```python
# åœ¨ FiLMedPrismaticVisionBackboneAggregator.forward()
avg_lang = language_embeddings.mean(dim=1)  # [B, 20, 4096] â†’ [B, 4096]
```

**ä½œç”¨**: å°†20ä¸ªtokençš„æŒ‡ä»¤å‹ç¼©æˆ1ä¸ªå…¨å±€è¯­ä¹‰å‘é‡

---

### **æ­¥éª¤2: åˆ†ç¦»å›¾åƒ**

```python
# åˆ†ç¦»3å¼ å›¾ï¼ˆæ¯å¼ 6é€šé“ï¼‰
images = torch.split(pixel_values, [6, 6, 6], dim=1)
# â†’ img1[B,6,224,224], img2[B,6,224,224], img3[B,6,224,224]
```

**3å¼ å›¾é€šå¸¸æ˜¯**:
- img1: Primary cameraï¼ˆä¸»è§†è§’ï¼‰
- img2: Wrist camera 1ï¼ˆæ‰‹è…•ç›¸æœº1ï¼‰
- img3: Wrist camera 2ï¼ˆæ‰‹è…•ç›¸æœº2ï¼‰

---

### **æ­¥éª¤3: å¾ªç¯å¤„ç†æ¯å¼ å›¾**

```python
for img in images:  # å¤„ç†3æ¬¡
    # 3.1 åˆ†ç¦»åŒç¼–ç å™¨è¾“å…¥
    img_regular, img_fused = torch.split(img, [3, 3], dim=1)
    # img_regular: [B, 3, 224, 224]  â† ç»™SigLIP
    # img_fused:   [B, 3, 224, 224]  â† ç»™DINOv2
    # æ³¨æ„: æ˜¯åŒä¸€å¼ RGBå›¾ï¼Œå¤åˆ¶äº†ä¸¤ä»½ï¼
    
    # 3.2 é€šè¿‡åŒç¼–ç å™¨
    patches_siglip = self.vision_backbone.featurizer(img_regular, avg_lang)
    patches_dino = self.vision_backbone.fused_featurizer(img_fused, avg_lang)
```

**åŒç¼–ç å™¨**:
- **SigLIP**: æ“…é•¿è¯­ä¹‰è¯†åˆ«ï¼ˆ"è¿™æ˜¯è‹¹æœ"ï¼‰
- **DINOv2**: æ“…é•¿å‡ ä½•å®šä½ï¼ˆ"åœ¨å·¦è¾¹"ï¼‰

---

### **æ­¥éª¤4: å•ä¸ªViTå†…éƒ¨å¤„ç†**ï¼ˆå…³é”®ï¼ï¼‰

ä»¥`featurizer`ï¼ˆSigLIPï¼‰ä¸ºä¾‹ï¼š

```python
# 4.1 è°ƒç”¨è¢«æ›¿æ¢çš„forward
featurizer(img_regular, avg_lang)
  â†“ (forwardå·²è¢«monkey-patch)
  â†“
# 4.2 å®é™…æ‰§è¡Œ get_intermediate_layers
get_intermediate_layers(img_regular, avg_lang, vision_aggr=[1,64,1024], n=25)
  â†“
# 4.3 å†…éƒ¨è°ƒç”¨ _intermediate_layers
_intermediate_layers():
    x = patch_embed(img_regular)              # [B, 256, 1024] - å›¾åƒåˆ†patch
    x = cat([x, vision_aggr_tokens])          # [B, 320, 1024] - æ‹¼æ¥64ä¸ªèšåˆtoken
    
    # 4.4 é€šè¿‡27å±‚Transformer
    for blk in blocks (0-26):
        # æ¯å±‚éƒ½åšFiLMè°ƒåˆ¶
        gamma = MLP(avg_lang)  # [B, 1024] ç¼©æ”¾ç³»æ•°
        beta = MLP(avg_lang)   # [B, 1024] åç§»ç³»æ•°
        
        x = attention(x)       # 320ä¸ªtokenäº’ç›¸çœ‹
        x = x * (1+gamma) + beta  # ğŸ”¥ æ–‡æœ¬è°ƒåˆ¶è§†è§‰ï¼
        x = mlp(x)
  â†“
# 4.5 æå–aggregation tokens
output = x[:, 256:]  # [B, 320, 1024] â†’ [B, 64, 1024]
                     # ä¸¢å¼ƒå‰256ä¸ªpatchï¼Œåªä¿ç•™64ä¸ªèšåˆtoken
```

**å…³é”®æœºåˆ¶**:
- **Aggregation Tokens**: 256ä¸ªpatchå‹ç¼©åˆ°64ä¸ªtoken
- **FiLMè°ƒåˆ¶**: ç”¨æ–‡æœ¬`avg_lang`åŠ¨æ€è°ƒæ•´è§†è§‰ç‰¹å¾

---

### **æ­¥éª¤5: æ”¶é›†è¾“å‡º**

```python
# å¤„ç†å®Œ3å¼ å›¾å
all_patches = [
    (siglip1[B,64,1024], dino1[B,64,1152]),  # å›¾1
    (siglip2[B,64,1024], dino2[B,64,1152]),  # å›¾2
    (siglip3[B,64,1024], dino3[B,64,1152])   # å›¾3
]
return all_patches
```

---

## ğŸ“Š æ•°æ®æµå›¾è§£

```
pixel_values [B,18,224,224] + language_embeddings [B,20,4096]
                    â†“
            avg_lang = mean()  [B,4096]
                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“           â†“           â†“
      img1        img2        img3
    [B,6,224]   [B,6,224]   [B,6,224]
        â†“           â†“           â†“
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
SigLIP DINOv2  SigLIP DINOv2  SigLIP DINOv2
    â†“     â†“       â†“     â†“       â†“     â†“
  [64] [64]     [64] [64]     [64] [64]  â† aggregation tokens
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
        â†“           â†“           â†“
     è¾“å‡º1        è¾“å‡º2        è¾“å‡º3
```

---

## ğŸ¯ æ ¸å¿ƒè¦ç‚¹

### 1ï¸âƒ£ **åŒç¼–ç å™¨æ¶æ„**
- åŒä¸€å¼ å›¾é€å…¥ä¸¤ä¸ªç¼–ç å™¨
- SigLIP (è¯­ä¹‰) + DINOv2 (å‡ ä½•) = äº’è¡¥ç‰¹å¾

### 2ï¸âƒ£ **Aggregation Tokens**
- æ¯ä¸ªViT: 256 patches â†’ 64 aggregation tokens
- å‹ç¼©æ¯”: 75% (å¤§å¹…å‡å°‘åç»­LLMè®¡ç®—é‡)

### 3ï¸âƒ£ **FiLMè°ƒåˆ¶**
- æ–‡æœ¬æŒ‡ä»¤åŠ¨æ€å½±å“è§†è§‰ç¼–ç 
- å…¬å¼: `x_new = x * (1 + Î³(text)) + Î²(text)`
- ä¸åŒæŒ‡ä»¤ â†’ ä¸åŒè§†è§‰è¡¨ç¤º

### 4ï¸âƒ£ **è¾“å‡ºæ ¼å¼**
- 3å¼ å›¾ Ã— 2ä¸ªç¼–ç å™¨ = 6ç»„ç‰¹å¾
- æ¯ç»„: [B, 64, embed_dim]
- åç»­é€šè¿‡MoE Routerèåˆ

---

## ğŸ’» æ ¸å¿ƒä»£ç å®ç°è¯¦è§£

### **æœºåˆ¶1: 256 Patches â†’ 64 Aggregation Tokens**

**ä»£ç ä½ç½®**: `prismatic/models/vit_wrapper_reg.py:_intermediate_layers`

```python
# æ­¥éª¤1: æ ‡å‡†patch embedding
x = self.patch_embed(x)      # [B, 3, 224, 224] â†’ [B, 256, 1024]
x = self._pos_embed(x)        # æ·»åŠ ä½ç½®ç¼–ç 
x = self.norm_pre(x)

# ğŸ”¥ æ­¥éª¤2: æ‹¼æ¥aggregation tokens (å…³é”®!)
vision_aggr_batch = vision_aggr.expand(x.shape[0], -1, -1)  
# vision_aggr:       [1, 64, 1024]  (å¯å­¦ä¹ å‚æ•°)
# vision_aggr_batch: [B, 64, 1024]  (expandåˆ°batch size)

x = torch.cat([x, vision_aggr_batch], dim=1)
# æ‹¼æ¥ç»“æœ: [B, 320, 1024]
#          [256ä¸ªpatches + 64ä¸ªaggregation tokens]

# æ­¥éª¤3: é€šè¿‡Transformeräº¤äº’
for i, blk in enumerate(self.blocks):  # 27å±‚
    x = blk(x, language_embeddings)    
    # æ‰€æœ‰320ä¸ªtokenä¸€èµ·åšself-attention
    # aggregation tokensé€šè¿‡attention "å¸æ”¶" patchä¿¡æ¯

# ğŸ”¥ æ­¥éª¤4: åªä¿ç•™aggregation tokens (åœ¨get_intermediate_layersä¸­)
outputs = [out[:, 256:] for out in outputs]  # [B, 320, 1024] â†’ [B, 64, 1024]
#              â†‘ è·³è¿‡å‰256ä¸ªpatchesï¼Œåªä¿ç•™å64ä¸ªaggregation tokens
```

**æ ¸å¿ƒåŸç†**: 
- Aggregation tokensé€šè¿‡27å±‚çš„self-attentionï¼Œä¸æ–­ä¸256ä¸ªpatchäº¤äº’
- æœ€ç»ˆ"å­¦ä¼š"å¦‚ä½•æ€»ç»“æ•´å¼ å›¾åƒçš„ä¿¡æ¯
- è¾“å‡ºæ—¶ä¸¢å¼ƒpatchesï¼Œåªä¿ç•™aggregation tokens â†’ å®ç°75%å‹ç¼©

---

### **æœºåˆ¶2: FiLMè°ƒåˆ¶å…¬å¼å®ç°**

**ä»£ç ä½ç½®**: `prismatic/models/film_vit_wrapper.py:FiLMedVisionTransformerBlock.forward`

```python
def forward(self, x, average_language_embedding):
    # ğŸ”¥ æ­¥éª¤1: ä»æ–‡æœ¬ç”Ÿæˆ gamma å’Œ beta
    gamma = self.scale(average_language_embedding)  # [B, 4096] â†’ [B, 1024]
    beta = self.shift(average_language_embedding)   # [B, 4096] â†’ [B, 1024]
    #        â†‘ Linearå±‚                â†‘ æ–‡æœ¬å…¨å±€å‘é‡
    
    # æ­¥éª¤2: Attention
    x = x + self.block.attn(self.block.norm1(x))
    
    # ğŸ”¥ æ­¥éª¤3: FiLMè°ƒåˆ¶ (L72)
    x = x * (1 + gamma.view(gamma.shape[0], 1, gamma.shape[1])) + beta.view(...)
    #   â†‘     â†‘ ç¼©æ”¾                                              â†‘ åç§»
    # åŸå§‹   1+Î³ (åˆå§‹åŒ–æ¥è¿‘identity)                           Î²
    
    # æ­¥éª¤4: MLP
    x = x + self.block.mlp(self.block.norm2(x))
    return x
```

**å±•å¼€è¯´æ˜**:
```python
# gamma, beta shape: [B, 1024]
# x shape: [B, 320, 1024]  (320ä¸ªtoken)

# å¹¿æ’­æœºåˆ¶:
gamma_expanded = gamma.view(B, 1, 1024)  # [B, 1, 1024]
beta_expanded = beta.view(B, 1, 1024)    # [B, 1, 1024]

# å¯¹æ¯ä¸ªtokençš„æ¯ä¸ªç»´åº¦åš:
x[b,i,d] = x[b,i,d] * (1 + gamma[b,d]) + beta[b,d]
#          åŸå§‹å€¼      æ–‡æœ¬å†³å®šçš„ç¼©æ”¾    æ–‡æœ¬å†³å®šçš„åç§»
```

**ä½œç”¨ç¤ºä¾‹**:
```python
# æŒ‡ä»¤: "pick up the red apple"
gamma = [0.5, -0.2, 0.8, ...]  # å¼ºè°ƒæŸäº›ç»´åº¦
beta = [0.1, 0.05, -0.1, ...]  # è°ƒæ•´åŸºçº¿

# å¯¹è§†è§‰ç‰¹å¾ x = [2.0, 1.5, 0.3, ...]
x_new[0] = 2.0 * (1+0.5) + 0.1 = 3.1   # æ”¾å¤§
x_new[1] = 1.5 * (1-0.2) + 0.05 = 1.25 # ç¼©å°
x_new[2] = 0.3 * (1+0.8) - 0.1 = 0.44  # è°ƒæ•´

# ç»“æœ: æ–‡æœ¬"å‘Šè¯‰"è§†è§‰ç¼–ç å™¨å“ªäº›ç‰¹å¾æ›´é‡è¦
```

---

## ğŸ” å¸¸è§ç–‘é—®

**Q: ä¸ºä»€ä¹ˆ6é€šé“ï¼Ÿ**  
A: åŒä¸€å¼ RGBå›¾å¤åˆ¶ä¸¤ä»½ï¼Œåˆ†åˆ«ç»™SigLIP(å‰3é€šé“)å’ŒDINOv2(å3é€šé“)

**Q: aggregation tokenså¦‚ä½•å·¥ä½œï¼Ÿ**  
A: é€šè¿‡self-attentionä¸256ä¸ªpatchäº¤äº’ï¼Œ"å¸æ”¶"å…¨å›¾ä¿¡æ¯ï¼Œæœ€ç»ˆåªä¿ç•™è¿™64ä¸ªtoken

**Q: FiLMåœ¨å“ªé‡Œä½œç”¨ï¼Ÿ**  
A: åœ¨ViTçš„æ¯ä¸€å±‚ï¼Œattentionä¹‹åã€MLPä¹‹å‰ (L72: `x = x * (1+Î³) + Î²`)

**Q: ä¸ºä»€ä¹ˆè¦mean(dim=1)ï¼Ÿ**  
A: æŠŠå˜é•¿æŒ‡ä»¤(20ä¸ªtoken)å‹ç¼©æˆå›ºå®šé•¿åº¦(1ä¸ªå‘é‡)ï¼Œä¾¿äºFiLMä½¿ç”¨

**Q: Batch size Bæ˜¯ä»€ä¹ˆï¼Ÿ**  
A: è®­ç»ƒæ—¶åŒæ—¶å¤„ç†çš„æ ·æœ¬æ•°é‡ã€‚mean(dim=1)åæ¯ä¸ªæ ·æœ¬éƒ½æœ‰è‡ªå·±çš„å…¨å±€è¯­ä¹‰å‘é‡

---

## ğŸ“ åç»­å¤„ç†ï¼šMoE Routerï¼ˆVision Backboneå¤–éƒ¨ï¼‰

> âš ï¸ **é‡è¦**ï¼šMoE Router **ä¸å±äº** Vision Backbone å†…éƒ¨ï¼Œä½†å®ƒæ˜¯ Vision Backbone è¾“å‡ºçš„**ä¸‹ä¸€ä¸ªå¤„ç†æ­¥éª¤**

### æ¶æ„ä½ç½®

```python
# modeling_prismatic.py
class PrismaticForConditionalGeneration:
    def __init__(self):
        # 1ï¸âƒ£ Vision Backboneï¼ˆç‹¬ç«‹ç»„ä»¶ï¼‰
        self.vision_backbone = PrismaticVisionBackbone(...)
        
        # 2ï¸âƒ£ MoE Routerï¼ˆæ¨¡å‹é¡¶å±‚ï¼Œä¸vision_backboneå¹³çº§ï¼‰
        self.aggregation_router = MoEAggregator(...)
        self.featurizer_proj = nn.Linear(...)       # SigLIPæŠ•å½±
        self.fused_featurizer_proj = nn.Linear(...) # DINOæŠ•å½±
```

**å¤„ç†æµç¨‹**ï¼š
```
Vision Backbone â†’ æŠ•å½±å±‚ â†’ MoE Router â†’ å¤šæ¨¡æ€åºåˆ—
  (å†…éƒ¨ç»„ä»¶)    (çº¿æ€§å˜æ¢)  (å¤–éƒ¨ç»„ä»¶)   (é€å…¥LLM)
```

---

### MoE Router å·¥ä½œæœºåˆ¶

**è¾“å…¥**ï¼ˆæ¥è‡ªVision Backboneï¼‰ï¼š
```python
patches_siglip: [B, 64, 1024]  # SigLIPè¾“å‡ºï¼ˆå·²è¢«FiLMè°ƒåˆ¶ï¼‰
patches_dino:   [B, 64, 1152]  # DINOè¾“å‡ºï¼ˆå·²è¢«FiLMè°ƒåˆ¶ï¼‰
avg_lang:       [B, 4096]       # æ–‡æœ¬å…¨å±€å‘é‡
```

**æ­¥éª¤1ï¼šæŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦**
```python
proj_siglip = self.featurizer_proj(patches_siglip)      # [B, 64, 4096]
proj_dino = self.fused_featurizer_proj(patches_dino)    # [B, 64, 4096]
```

**æ­¥éª¤2ï¼šMoE Router å†³å®šèåˆæƒé‡**
```python
# ä»£ç ä½ç½®: prismatic/models/router.py
def forward(self, inputs_embeds, seq_embeds):
    # inputs_embeds = [proj_siglip, proj_dino]
    # seq_embeds = avg_lang
    
    # æ–‡æœ¬ â†’ æƒé‡
    logits = self.router(seq_embeds)  # [B, 4096] â†’ [B, 2]
    # router = MLP: Linear(4096â†’4096) â†’ GELU â†’ Linear(4096â†’2)
    
    ratios = torch.softmax(logits, dim=-1)  # [B, 2]
    # ä¾‹å¦‚: [0.7, 0.3]
    
    # åŠ æƒæ±‚å’Œ
    output = ratios[:, 0].view(-1,1,1) * proj_siglip + \
             ratios[:, 1].view(-1,1,1) * proj_dino
    # [B, 64, 4096]
    
    return output
```

**è¾“å‡º**ï¼š
```python
fused_features: [B, 64, 4096]  # èåˆåçš„è§†è§‰tokens
```

---

### ğŸ”„ MoE Router vs FiLM å¯¹æ¯”

| ç»´åº¦ | FiLMè°ƒåˆ¶ | MoE Router |
|------|----------|------------|
| **ä½ç½®** | Vision Backboneå†…éƒ¨ | Vision Backboneå¤–éƒ¨ |
| **å±‚çº§** | ViTæ¯å±‚ï¼ˆ27å±‚ï¼‰ | 1æ¬¡å…¨å±€æ“ä½œ |
| **äº¤äº’æ·±åº¦** | æ·±åº¦ï¼ˆä¿®æ”¹ç‰¹å¾å€¼ï¼‰ | æµ…å±‚ï¼ˆåŠ æƒå¹³å‡ï¼‰ |
| **ç²’åº¦** | Per-dimensionï¼ˆ1024ç»´ï¼‰ | Per-sampleï¼ˆ2ä¸ªæ ‡é‡ï¼‰ |
| **æœºåˆ¶** | `x = x*(1+Î³)+Î²` | `out = w1*x1 + w2*x2` |
| **ä¿¡æ¯æµ** | æ–‡æœ¬â†’è§†è§‰ç‰¹å¾ | æ–‡æœ¬â†’æƒé‡â†’è§†è§‰ |
| **ä½œç”¨** | è°ƒåˆ¶ç‰¹å¾å†…å®¹ | é€‰æ‹©ä¸“å®¶æƒé‡ |

---

### ğŸ“Š å®Œæ•´æ•°æ®æµï¼ˆå«MoEï¼‰

```
pixel_values [B,18,224,224] + language_embeddings [B,20,4096]
                    â†“
            avg_lang = mean()  [B,4096]
                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Vision Backbone å†…éƒ¨å¤„ç†
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        â†“           â†“           â†“
      img1        img2        img3
    [B,6,224]   [B,6,224]   [B,6,224]
        â†“           â†“           â†“
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
ğŸ”¥ FiLMè°ƒåˆ¶ï¼ˆ27å±‚ï¼Œæ·±åº¦äº¤äº’ï¼‰
    â†“     â†“       â†“     â†“       â†“     â†“
ğŸ¯ Aggregationï¼ˆSelf-Attentionå‹ç¼©ï¼‰
    â†“     â†“       â†“     â†“       â†“     â†“
SigLIP DINOv2  SigLIP DINOv2  SigLIP DINOv2
  [64] [64]     [64] [64]     [64] [64]
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Vision Backbone è¾“å‡º
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        â†“           â†“           â†“
    æŠ•å½±å±‚ï¼ˆçº¿æ€§å˜æ¢ï¼‰
        â†“           â†“           â†“
    [B,64,4096] [B,64,4096] [B,64,4096]
        â†“           â†“           â†“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸšï¸ MoE Routerï¼ˆæ¡ä»¶åŒ–åŠ æƒï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   0.7*SigLIP + 0.3*DINO (æ¯å¼ å›¾)
        â†“           â†“           â†“
    [B,64,4096] [B,64,4096] [B,64,4096]
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
        concatenate (æ‹¼æ¥3å¼ å›¾)
                    â†“
            [B, 192, 4096]
                    â†“
        é€å…¥ LLM æ„å»ºå¤šæ¨¡æ€åºåˆ—
```

---

### ğŸ’¡ å…³é”®ç†è§£

1. **æ¶æ„åˆ†å±‚**ï¼š
   - **Vision Backbone**ï¼šè´Ÿè´£ç‰¹å¾æå–ï¼ˆåŒç¼–ç å™¨+FiLM+Aggregationï¼‰
   - **MoE Router**ï¼šè´Ÿè´£ä¸“å®¶èåˆï¼ˆåœ¨Backboneå¤–éƒ¨ï¼‰

2. **äº¤äº’å±‚æ¬¡**ï¼š
   - **FiLM**ï¼ˆæ·±å±‚ï¼‰ï¼šæ–‡æœ¬ç»†ç²’åº¦è°ƒåˆ¶è§†è§‰ç‰¹å¾ï¼ˆ1024ç»´ï¼‰
   - **MoE**ï¼ˆæµ…å±‚ï¼‰ï¼šæ–‡æœ¬å†³å®šä¸“å®¶æƒé‡ï¼ˆ2ä¸ªæ ‡é‡ï¼‰

3. **è®¾è®¡å“²å­¦**ï¼š
   - FiLM: "ä»€ä¹ˆç‰¹å¾é‡è¦ï¼Ÿ"ï¼ˆWhatï¼‰
   - MoE: "ç”¨å“ªä¸ªä¸“å®¶ï¼Ÿ"ï¼ˆWhichï¼‰

4. **æ²¡æœ‰Cross-Attention**ï¼š
   - MoE Router åªæ˜¯ç®€å•çš„åŠ æƒå¹³å‡
   - ä¸æ˜¯æ³¨æ„åŠ›æœºåˆ¶ï¼Œåªæ˜¯æ¡ä»¶åŒ–åŠ æƒ

---

### ğŸ”— ç›¸å…³æ–‡æ¡£

- å®Œæ•´çš„è§†è§‰-è¯­è¨€äº¤äº’æµç¨‹ï¼š[vision_language_interaction_flow.md](./vision_language_interaction_flow.md)
- CogVLAè®­ç»ƒæµç¨‹ï¼š[CogVLA_TRAINING_FLOW.md](./CogVLA_TRAINING_FLOW.md)
